{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e48f4e5",
   "metadata": {},
   "source": [
    "ISIC 2019\n",
    "\n",
    "Total samples: 25,331\n",
    "\n",
    "Benign: 82.15 %\n",
    "\n",
    "Melanoma: 17.85 %\n",
    "\n",
    "HAM10000\n",
    "\n",
    "Total samples: 10,015\n",
    "\n",
    "Benign: 88.89 %\n",
    "\n",
    "Melanoma: 11.11 %"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ca2200",
   "metadata": {},
   "source": [
    "Check Folders Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab721aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ Folder Structure (Directories Only)\n",
      "ğŸ“ Root: c:\\Users\\umair\\Videos\\PhD\\PhD Data\\Week 8 Jannuary\\Code\n",
      "\n",
      "â”œâ”€â”€ .git\n",
      "â”‚   â”œâ”€â”€ hooks\n",
      "â”‚   â”œâ”€â”€ info\n",
      "â”‚   â”œâ”€â”€ logs\n",
      "â”‚   â”‚   â””â”€â”€ refs\n",
      "â”‚   â”‚       â”œâ”€â”€ heads\n",
      "â”‚   â”‚       â””â”€â”€ remotes\n",
      "â”‚   â”‚           â””â”€â”€ origin\n",
      "â”‚   â”œâ”€â”€ objects\n",
      "â”‚   â”‚   â”œâ”€â”€ 02\n",
      "â”‚   â”‚   â”œâ”€â”€ 17\n",
      "â”‚   â”‚   â”œâ”€â”€ 1a\n",
      "â”‚   â”‚   â”œâ”€â”€ 1e\n",
      "â”‚   â”‚   â”œâ”€â”€ 1f\n",
      "â”‚   â”‚   â”œâ”€â”€ 28\n",
      "â”‚   â”‚   â”œâ”€â”€ 3c\n",
      "â”‚   â”‚   â”œâ”€â”€ 3f\n",
      "â”‚   â”‚   â”œâ”€â”€ 45\n",
      "â”‚   â”‚   â”œâ”€â”€ 4f\n",
      "â”‚   â”‚   â”œâ”€â”€ 58\n",
      "â”‚   â”‚   â”œâ”€â”€ 5e\n",
      "â”‚   â”‚   â”œâ”€â”€ 64\n",
      "â”‚   â”‚   â”œâ”€â”€ 67\n",
      "â”‚   â”‚   â”œâ”€â”€ 75\n",
      "â”‚   â”‚   â”œâ”€â”€ 78\n",
      "â”‚   â”‚   â”œâ”€â”€ 79\n",
      "â”‚   â”‚   â”œâ”€â”€ 7d\n",
      "â”‚   â”‚   â”œâ”€â”€ 80\n",
      "â”‚   â”‚   â”œâ”€â”€ 81\n",
      "â”‚   â”‚   â”œâ”€â”€ 83\n",
      "â”‚   â”‚   â”œâ”€â”€ 8e\n",
      "â”‚   â”‚   â”œâ”€â”€ 9a\n",
      "â”‚   â”‚   â”œâ”€â”€ 9c\n",
      "â”‚   â”‚   â”œâ”€â”€ a5\n",
      "â”‚   â”‚   â”œâ”€â”€ a9\n",
      "â”‚   â”‚   â”œâ”€â”€ ab\n",
      "â”‚   â”‚   â”œâ”€â”€ b1\n",
      "â”‚   â”‚   â”œâ”€â”€ b5\n",
      "â”‚   â”‚   â”œâ”€â”€ b8\n",
      "â”‚   â”‚   â”œâ”€â”€ c1\n",
      "â”‚   â”‚   â”œâ”€â”€ c9\n",
      "â”‚   â”‚   â”œâ”€â”€ e0\n",
      "â”‚   â”‚   â”œâ”€â”€ e2\n",
      "â”‚   â”‚   â”œâ”€â”€ e4\n",
      "â”‚   â”‚   â”œâ”€â”€ e6\n",
      "â”‚   â”‚   â”œâ”€â”€ f2\n",
      "â”‚   â”‚   â”œâ”€â”€ f8\n",
      "â”‚   â”‚   â”œâ”€â”€ f9\n",
      "â”‚   â”‚   â”œâ”€â”€ fc\n",
      "â”‚   â”‚   â”œâ”€â”€ info\n",
      "â”‚   â”‚   â””â”€â”€ pack\n",
      "â”‚   â””â”€â”€ refs\n",
      "â”‚       â”œâ”€â”€ heads\n",
      "â”‚       â”œâ”€â”€ remotes\n",
      "â”‚       â”‚   â””â”€â”€ origin\n",
      "â”‚       â””â”€â”€ tags\n",
      "â”œâ”€â”€ CleanData\n",
      "â”‚   â”œâ”€â”€ HAM10000\n",
      "â”‚   â”‚   â”œâ”€â”€ images\n",
      "â”‚   â”‚   â””â”€â”€ segmentations\n",
      "â”‚   â””â”€â”€ ISIC2019\n",
      "â”‚       â”œâ”€â”€ images_test\n",
      "â”‚       â””â”€â”€ images_train\n",
      "â”œâ”€â”€ Datasets\n",
      "â”‚   â”œâ”€â”€ HAM10000\n",
      "â”‚   â”‚   â”œâ”€â”€ HAM10000_images_part_1\n",
      "â”‚   â”‚   â”œâ”€â”€ HAM10000_images_part_2\n",
      "â”‚   â”‚   â”œâ”€â”€ HAM10000_segmentations_lesion_tschandl\n",
      "â”‚   â”‚   â”‚   â”œâ”€â”€ HAM10000_segmentations_lesion_tschandl\n",
      "â”‚   â”‚   â”‚   â””â”€â”€ __MACOSX\n",
      "â”‚   â”‚   â”‚       â””â”€â”€ HAM10000_segmentations_lesion_tschandl\n",
      "â”‚   â”‚   â””â”€â”€ ISIC2018_Task3_Test_Images\n",
      "â”‚   â”‚       â”œâ”€â”€ ISIC2018_Task3_Test_Images\n",
      "â”‚   â”‚       â””â”€â”€ __MACOSX\n",
      "â”‚   â”‚           â””â”€â”€ ISIC2018_Task3_Test_Images\n",
      "â”‚   â””â”€â”€ ISIC 2019\n",
      "â”‚       â”œâ”€â”€ ISIC_2019_Test_Input\n",
      "â”‚       â””â”€â”€ ISIC_2019_Training_Input\n",
      "â”œâ”€â”€ csv_outputs\n",
      "â”œâ”€â”€ features\n",
      "â”‚   â””â”€â”€ __pycache__\n",
      "â”œâ”€â”€ lcs\n",
      "â”‚   â””â”€â”€ __pycache__\n",
      "â””â”€â”€ scikit-ExSTraCS-master\n",
      "    â”œâ”€â”€ defaultExportDir\n",
      "    â”œâ”€â”€ skExSTraCS\n",
      "    â”‚   â””â”€â”€ __pycache__\n",
      "    â””â”€â”€ test\n",
      "        â””â”€â”€ DataSets\n",
      "            â”œâ”€â”€ Real\n",
      "            â””â”€â”€ Tests\n",
      "                â”œâ”€â”€ NumericTests\n",
      "                â””â”€â”€ SpecificityTests\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def print_folders_only(root_dir, prefix=\"\"):\n",
    "    try:\n",
    "        entries = sorted(\n",
    "            [e for e in os.listdir(root_dir)\n",
    "             if os.path.isdir(os.path.join(root_dir, e))]\n",
    "        )\n",
    "    except PermissionError:\n",
    "        print(prefix + \"â””â”€â”€ [Permission Denied]\")\n",
    "        return\n",
    "\n",
    "    for i, folder in enumerate(entries):\n",
    "        path = os.path.join(root_dir, folder)\n",
    "        is_last = (i == len(entries) - 1)\n",
    "\n",
    "        connector = \"â””â”€â”€ \" if is_last else \"â”œâ”€â”€ \"\n",
    "        print(prefix + connector + folder)\n",
    "\n",
    "        extension = \"    \" if is_last else \"â”‚   \"\n",
    "        print_folders_only(path, prefix + extension)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ROOT_DIR = os.getcwd()   # current directory\n",
    "    print(f\"\\nğŸ“ Folder Structure (Directories Only)\\nğŸ“ Root: {ROOT_DIR}\\n\")\n",
    "    print_folders_only(ROOT_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee5e100",
   "metadata": {},
   "source": [
    "Clean Folder Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7788d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "ROOT = os.getcwd()\n",
    "DATASETS = os.path.join(ROOT, \"Datasets\")\n",
    "CLEAN = os.path.join(ROOT, \"CleanData\")\n",
    "\n",
    "IMG_EXTS = (\".jpg\", \".jpeg\", \".png\")\n",
    "\n",
    "def safe_mkdir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "        print(f\"[CREATE] {path}\")\n",
    "\n",
    "def move_images(src, dst):\n",
    "    if not os.path.exists(src):\n",
    "        print(f\"[SKIP] Missing: {src}\")\n",
    "        return\n",
    "\n",
    "    safe_mkdir(dst)\n",
    "\n",
    "    for root, dirs, files in os.walk(src):\n",
    "        # ignore macOS junk\n",
    "        dirs[:] = [d for d in dirs if d != \"__MACOSX\"]\n",
    "\n",
    "        for f in files:\n",
    "            if f.lower().endswith(IMG_EXTS):\n",
    "                src_file = os.path.join(root, f)\n",
    "                dst_file = os.path.join(dst, f)\n",
    "\n",
    "                if os.path.exists(dst_file):\n",
    "                    print(f\"[SKIP] Exists: {dst_file}\")\n",
    "                    continue\n",
    "\n",
    "                shutil.move(src_file, dst_file)\n",
    "                print(f\"[MOVE] {f}\")\n",
    "\n",
    "def main():\n",
    "    print(\"\\n=== MOVING IMAGES TO CLEAN WORKSPACE (NO COPY) ===\\n\")\n",
    "\n",
    "    safe_mkdir(CLEAN)\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # HAM10000\n",
    "    # -------------------------------------------------\n",
    "    print(\"--- HAM10000 ---\")\n",
    "\n",
    "    ham_clean = os.path.join(CLEAN, \"HAM10000\")\n",
    "    safe_mkdir(ham_clean)\n",
    "\n",
    "    move_images(\n",
    "        os.path.join(DATASETS, \"HAM10000\", \"HAM10000_images_part_1\"),\n",
    "        os.path.join(ham_clean, \"images\")\n",
    "    )\n",
    "\n",
    "    move_images(\n",
    "        os.path.join(DATASETS, \"HAM10000\", \"HAM10000_images_part_2\"),\n",
    "        os.path.join(ham_clean, \"images\")\n",
    "    )\n",
    "\n",
    "    move_images(\n",
    "        os.path.join(DATASETS, \"HAM10000\", \"HAM10000_segmentations_lesion_tschandl\"),\n",
    "        os.path.join(ham_clean, \"segmentations\")\n",
    "    )\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # ISIC 2019\n",
    "    # -------------------------------------------------\n",
    "    print(\"\\n--- ISIC2019 ---\")\n",
    "\n",
    "    isic_clean = os.path.join(CLEAN, \"ISIC2019\")\n",
    "    safe_mkdir(isic_clean)\n",
    "\n",
    "    move_images(\n",
    "        os.path.join(DATASETS, \"ISIC 2019\", \"ISIC_2019_Training_Input\"),\n",
    "        os.path.join(isic_clean, \"images_train\")\n",
    "    )\n",
    "\n",
    "    move_images(\n",
    "        os.path.join(DATASETS, \"ISIC 2019\", \"ISIC_2019_Test_Input\"),\n",
    "        os.path.join(isic_clean, \"images_test\")\n",
    "    )\n",
    "\n",
    "    print(\"\\n=== DONE (IMAGES MOVED, NO DELETION) ===\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0318ad",
   "metadata": {},
   "source": [
    "Corruprted Imaages Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cd1fc94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking: CleanData/HAM10000/images\n",
      "Corrupted: None âœ…\n",
      "\n",
      "Checking: CleanData/ISIC2019/images_train\n",
      "Corrupted: None âœ…\n",
      "\n",
      "Checking: CleanData/ISIC2019/images_test\n",
      "Corrupted: None âœ…\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "IMG_EXTS = (\".jpg\", \".jpeg\", \".png\")\n",
    "\n",
    "def check_folder(folder):\n",
    "    bad = []\n",
    "    for f in os.listdir(folder):\n",
    "        if f.lower().endswith(IMG_EXTS):\n",
    "            path = os.path.join(folder, f)\n",
    "            img = cv2.imread(path)\n",
    "            if img is None:\n",
    "                bad.append(f)\n",
    "    return bad\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    paths = [\n",
    "        \"CleanData/HAM10000/images\",\n",
    "        \"CleanData/ISIC2019/images_train\",\n",
    "        \"CleanData/ISIC2019/images_test\"\n",
    "    ]\n",
    "\n",
    "    for p in paths:\n",
    "        print(f\"\\nChecking: {p}\")\n",
    "        bad = check_folder(p)\n",
    "        print(\"Corrupted:\", bad if bad else \"None âœ…\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78702710",
   "metadata": {},
   "source": [
    "Image Count Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6534efaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HAM10000: 10015 images\n",
      "ISIC2019 Train: 25331 images\n",
      "ISIC2019 Test: 8238 images\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "IMG_EXTS = (\".jpg\", \".jpeg\", \".png\")\n",
    "\n",
    "def count_images(folder):\n",
    "    return sum(\n",
    "        1 for f in os.listdir(folder)\n",
    "        if f.lower().endswith(IMG_EXTS)\n",
    "    )\n",
    "\n",
    "paths = {\n",
    "    \"HAM10000\": \"CleanData/HAM10000/images\",\n",
    "    \"ISIC2019 Train\": \"CleanData/ISIC2019/images_train\",\n",
    "    \"ISIC2019 Test\": \"CleanData/ISIC2019/images_test\",\n",
    "}\n",
    "\n",
    "for name, path in paths.items():\n",
    "    print(f\"{name}: {count_images(path)} images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "978cb959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: CleanData/HAM10000/labels_binary.csv\n",
      "Missing images: 0\n",
      "Total labeled images: 10015\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# UPDATE PATH if filename differs slightly\n",
    "META_PATH = \"C:/Users/umair/Videos/PhD/PhD Data/Week 8 Jannuary/Code/CleanData/HAM10000/HAM10000_metadata\"\n",
    "IMG_DIR = \"CleanData/HAM10000/images\"\n",
    "OUT_CSV = \"CleanData/HAM10000/labels_binary.csv\"\n",
    "\n",
    "def map_label(dx):\n",
    "    # Binary: MEL vs NON-MEL\n",
    "    return 1 if dx.lower() == \"mel\" else 0\n",
    "\n",
    "def main():\n",
    "    df = pd.read_csv(META_PATH)\n",
    "\n",
    "    records = []\n",
    "    missing = 0\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        img_name = row[\"image_id\"] + \".jpg\"\n",
    "        img_path = os.path.join(IMG_DIR, img_name)\n",
    "\n",
    "        if not os.path.exists(img_path):\n",
    "            missing += 1\n",
    "            continue\n",
    "\n",
    "        label = map_label(row[\"dx\"])\n",
    "        records.append([img_name, img_path, label])\n",
    "\n",
    "    out = pd.DataFrame(records, columns=[\"image\", \"path\", \"label\"])\n",
    "    out.to_csv(OUT_CSV, index=False)\n",
    "\n",
    "    print(f\"Saved: {OUT_CSV}\")\n",
    "    print(f\"Missing images: {missing}\")\n",
    "    print(f\"Total labeled images: {len(out)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b836a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: CleanData/ISIC2019/labels_binary.csv\n",
      "Missing images: 0\n",
      "Total labeled images: 25331\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# ---- PATHS (match your structure) ----\n",
    "META_PATH = \"C:\\\\Users\\\\umair\\\\Videos\\\\PhD\\\\PhD Data\\\\Week 8 Jannuary\\\\Code\\\\CleanData\\\\ISIC2019\\\\ISIC_2019_Training_GroundTruth.csv\"\n",
    "IMG_DIR = \"CleanData/ISIC2019/images_train\"\n",
    "OUT_CSV = \"CleanData/ISIC2019/labels_binary.csv\"\n",
    "\n",
    "def main():\n",
    "    df = pd.read_csv(META_PATH)\n",
    "\n",
    "    records = []\n",
    "    missing = 0\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        img_name = row[\"image\"] + \".jpg\"\n",
    "        img_path = os.path.join(IMG_DIR, img_name)\n",
    "\n",
    "        if not os.path.exists(img_path):\n",
    "            missing += 1\n",
    "            continue\n",
    "\n",
    "        # Binary classification: MEL vs NON-MEL\n",
    "        label = 1 if row[\"MEL\"] == 1 else 0\n",
    "\n",
    "        records.append([img_name, img_path, label])\n",
    "\n",
    "    out = pd.DataFrame(records, columns=[\"image\", \"path\", \"label\"])\n",
    "    out.to_csv(OUT_CSV, index=False)\n",
    "\n",
    "    print(f\"Saved: {OUT_CSV}\")\n",
    "    print(f\"Missing images: {missing}\")\n",
    "    print(f\"Total labeled images: {len(out)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4fadba",
   "metadata": {},
   "source": [
    "What is LBP (Local Binary Pattern)?\n",
    "\n",
    "LBP is a handcrafted texture descriptor that encodes local micro-patterns in an image.\n",
    "\n",
    "For each pixel:\n",
    "\n",
    "Compare it with its neighbors\n",
    "\n",
    "If neighbor â‰¥ center â†’ 1\n",
    "\n",
    "Else â†’ 0\n",
    "\n",
    "Concatenate bits â†’ binary number â†’ histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee5e90e",
   "metadata": {},
   "source": [
    "Skin lesions differ not only in color but also in micro-texture. LBP captures fine-scale textural variations such as irregular borders, roughness, and pigment granularity, which are clinically relevant indicators of malignancy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "786d68a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from skimage.feature import local_binary_pattern\n",
    "\n",
    "def extract_lbp(\n",
    "    image,\n",
    "    radius=1,\n",
    "    n_points=8,\n",
    "    method=\"uniform\",\n",
    "    n_bins=10\n",
    "):\n",
    "    \"\"\"\n",
    "    Extract LBP histogram features from a grayscale image.\n",
    "\n",
    "    Parameters:\n",
    "    - image: input BGR image\n",
    "    - radius: radius of LBP\n",
    "    - n_points: number of sampling points\n",
    "    - method: LBP method (uniform recommended)\n",
    "    - n_bins: histogram bins\n",
    "\n",
    "    Returns:\n",
    "    - 1D numpy array of LBP histogram features\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Compute LBP\n",
    "    lbp = local_binary_pattern(gray, n_points, radius, method)\n",
    "\n",
    "    # Histogram\n",
    "    hist, _ = np.histogram(\n",
    "        lbp.ravel(),\n",
    "        bins=n_bins,\n",
    "        range=(0, n_bins),\n",
    "        density=True\n",
    "    )\n",
    "\n",
    "    return hist.astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad662af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LBP feature length: 10\n",
      "[0.05273333 0.07977778 0.05538518 0.09934445 0.11282222 0.11996666\n",
      " 0.10085926 0.09474074 0.11718889 0.16718148]\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import features.lbp\n",
    "importlib.reload(features.lbp)\n",
    "import cv2\n",
    "from features.lbp import extract_lbp\n",
    "\n",
    "img = cv2.imread(\"CleanData/HAM10000/images/ISIC_0024306.jpg\")\n",
    "features = extract_lbp(img)\n",
    "\n",
    "print(\"LBP feature length:\", len(features))\n",
    "print(features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6df6244",
   "metadata": {},
   "source": [
    "GLCM captures second-order texture statistics such as contrast and homogeneity, describing how pixel intensities co-occur spatially, which complements the local micro-patterns captured by LBP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee28bb49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLCM feature length: 5\n",
      "[10.3674755   2.0494194   0.40197736  0.05172076  0.9946185 ]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from features.glcm import extract_glcm\n",
    "\n",
    "img = cv2.imread(\"CleanData/HAM10000/images/ISIC_0024306.jpg\")\n",
    "features = extract_glcm(img)\n",
    "\n",
    "print(\"GLCM feature length:\", len(features))\n",
    "print(features)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lcs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
